{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff137c-7492-46f4-aa20-5216d526339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.requirements import *\n",
    "from src.ssl_model import *\n",
    "from src.asr_model import *\n",
    "from src.audio_handler import *\n",
    "from src.tokenizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67cd21-70c3-4df5-b24d-804fe29dbfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"data\", \"metadata_normal.tsv\")\n",
    "cache_path = os.path.join(\"data\", \"cache_mmap\", \"asr\")\n",
    "text_path = os.path.join(\"data\", \"text\")\n",
    "token_path = os.path.join(\"data\", \"tokenizer.json\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "\n",
    "update_ver = 50_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09f344-a52e-424d-8b65-cda7e4b9c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(token_path):\n",
    "    text = load_text(text_path)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.build_vocab(text)\n",
    "    tokenizer.save(token_path)\n",
    "else:\n",
    "    tokenizer = Tokenizer.load(token_path)\n",
    "\n",
    "vocab_size = len(tokenizer)\n",
    "vocab = tokenizer.get_vocab()\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d574d-0f8d-4cd8-a564-51cbb25198c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_model = SSLModel().to(device)\n",
    "asr_model = ASRModel(\n",
    "    ssl_model=ssl_model,\n",
    "    vocab_size=len(tokenizer),\n",
    "    hidden_dim=256,\n",
    "    num_layers=4,\n",
    "    dropout=0.2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b3401-ed41-495d-848e-3682dbd20206",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dict = torch.load(os.path.join('models', 'ssl_model', f'ssl_model_prototype_{update_ver}.pth'))\n",
    "ssl_state_dict = checkpoint_dict['model_state_dict']\n",
    "ssl_model.load_state_dict(ssl_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4c3ac-0ba3-4d47-8ea9-a4dcc13bb752",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_dataset = ASRDataset(\n",
    "    metadata_path=data_path,\n",
    "    tokenizer=tokenizer,\n",
    "    cache_dir=cache_path,\n",
    "    top_db=TOP_DB\n",
    ")\n",
    "\n",
    "asr_dl = DataLoader(\n",
    "    dataset=asr_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_padding_asr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65b680-da8f-49c8-a1d0-33a2c1899973",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(asr_dataset)\n",
    "accum = 8\n",
    "epochs = 5\n",
    "steps_per_epoch = dataset_size // (batch_size * accum)\n",
    "T_max = epochs * steps_per_epoch\n",
    "warmup = int(0.05 * T_max)\n",
    "print(\"Dataset size: \", dataset_size)\n",
    "print(\"Batch size: \", batch_size)\n",
    "print(\"Steps per epoch: \", steps_per_epoch)\n",
    "print(\"Tmax: \", T_max)\n",
    "print(\"Warmup steps: \", warmup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db8ebe8-e784-4785-86e3-a98c13c4171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, asr_model.parameters()),\n",
    "    lr=3e-4,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "# Check optimizer has params\n",
    "print(f\"\\nOptimizer managing {sum(p.numel() for group in optimizer.param_groups for p in group['params']):,} parameters\")\n",
    "\n",
    "loss_fn = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-4,\n",
    "    total_steps=20_000,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "scaler = torch.GradScaler(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd1fe39-8ab0-430a-9bcd-1964d935209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_decoder = torchaudio.models.decoder.ctc_decoder(\n",
    "    lexicon=None,\n",
    "    tokens=vocab,\n",
    "    blank_token='<blank>',\n",
    "    sil_token='ред',\n",
    "    unk_word=None,\n",
    "    nbest=1,\n",
    "    beam_size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7402c3c-942c-4034-81fa-c9949b06a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, scheduler, num_updates, path):\n",
    "    checkpoint = {\n",
    "        'num_updates' : num_updates,\n",
    "        'model_state_dict' : model.state_dict(),\n",
    "        'optimizer_state_dict' : optimizer.state_dict(),\n",
    "        'scheduler_state_dict' : scheduler.state_dict()\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea26598-7680-4b5b-ab88-c91ec86d66d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_pass_features_lstm(asr_model, val_dl, device):\n",
    "    \"\"\"Test feature rank through Bi-LSTM model.\"\"\"\n",
    "    \n",
    "    asr_model.eval()\n",
    "    batch = next(iter(val_dl))\n",
    "    waveforms, targets, input_lengths, target_lengths = batch\n",
    "    waveforms = waveforms.to(device)\n",
    "    input_lengths = input_lengths.to(device)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"BI-LSTM FEATURE ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # SSL features\n",
    "        z = asr_model.encoder(waveforms).transpose(1, 2)\n",
    "        c = asr_model.context(z)\n",
    "        print(f\"\\n1. SSL Context output:\")\n",
    "        print(f\"   Shape: {c.shape}\")\n",
    "        rank = check_rank_single(c)\n",
    "        print(f\"   Effective rank (95%): {rank}/128\")\n",
    "        \n",
    "        # After multi-scale\n",
    "        z_multi = asr_model.multiscale(c)\n",
    "        z_div = z_multi + asr_model.diversify(z_multi)\n",
    "        print(f\"\\n2. After diversify:\")\n",
    "        print(f\"   Shape: {z_div.shape}\")\n",
    "        rank = check_rank_single(z_div)\n",
    "        print(f\"   Effective rank (95%): {rank}/128\")\n",
    "        \n",
    "        # Pack sequences\n",
    "        z_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            z_div, input_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        # Bi-LSTM\n",
    "        lstm_out, _ = asr_model.lstm(z_packed)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        print(f\"\\n3. After Bi-LSTM:\")\n",
    "        print(f\"   Shape: {lstm_out.shape}\")\n",
    "        rank = check_rank_single(lstm_out)\n",
    "        print(f\"   Effective rank (95%): {rank}/512\")  # 256*2\n",
    "        \n",
    "        # After projection\n",
    "        z_proj = asr_model.projection(lstm_out)\n",
    "        print(f\"\\n4. After projection:\")\n",
    "        print(f\"   Shape: {z_proj.shape}\")\n",
    "        rank = check_rank_single(z_proj)\n",
    "        print(f\"   Effective rank (95%): {rank}/128\")\n",
    "        \n",
    "        # Final output\n",
    "        logits = asr_model.symbol(z_proj)\n",
    "        print(f\"\\n5. Final logits:\")\n",
    "        print(f\"   Shape: {logits.shape}\")\n",
    "\n",
    "def check_rank_single(features):\n",
    "    \"\"\"Helper to check rank of single batch.\"\"\"\n",
    "    features_flat = features.reshape(-1, features.size(-1)).cpu()\n",
    "    U, S, V = torch.svd(features_flat)\n",
    "    explained = (S ** 2) / (S ** 2).sum()\n",
    "    rank_95 = (explained.cumsum(0) < 0.95).sum().item() + 1\n",
    "    return rank_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd31fe6-efa7-437c-a956-5063fa02fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze SSL\n",
    "asr_model.freeze_ssl()\n",
    "asr_model.to(device)\n",
    "\n",
    "# Check parameters\n",
    "params = asr_model.get_num_params()\n",
    "print(f\"Total params: {params['total']:,}\")\n",
    "print(f\"Trainable params: {params['trainable']:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_batch = next(iter(asr_dl))\n",
    "waveforms, targets, input_lengths, target_lengths = test_batch\n",
    "waveforms = waveforms.to(device)\n",
    "input_lengths = input_lengths.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    log_probs = asr_model(waveforms, input_lengths)\n",
    "    print(f\"Output shape: {log_probs.shape}\")  # (seq_len, batch, vocab)\n",
    "\n",
    "# Check feature rank\n",
    "test_forward_pass_features_lstm(asr_model, asr_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef6f4d-d0c1-4ef9-8808-16825a1654e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_asr(asr_model, asr_dl, optimizer, scaler, scheduler, loss_fn, epochs, device):\n",
    "    max_updates = 20_000\n",
    "    num_updates = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        total_loss = 0.0\n",
    "\n",
    "        asr_model.train()\n",
    "        \n",
    "        for i, batch in enumerate(tqdm(asr_dl)):\n",
    "            waveforms, targets, input_lengths, target_lengths = batch\n",
    "            waveforms = waveforms.to(device)\n",
    "            input_lengths = input_lengths.to(device)\n",
    "            target_lengths = target_lengths.to(device)\n",
    "            \n",
    "            with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "                log_probs = asr_model(waveforms, input_lengths) / accum\n",
    "                flat_targets = torch.cat(targets).to(device)\n",
    "                loss = loss_fn(log_probs, flat_targets, input_lengths, target_lengths)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            total_loss += loss.item() * accum\n",
    "            \n",
    "            if (i+1) % accum == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(asr_model.parameters(), max_norm=2.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                num_updates += 1\n",
    "            \n",
    "            if num_updates % 1_000 == 0:\n",
    "                save_path = os.path.join('models', 'asr_model', f'asr_model_prototype_{num_updates}.pth')\n",
    "                save_checkpoint(asr_model, optimizer, scheduler, num_updates, save_path)\n",
    "            \n",
    "            if num_updates >= max_updates:\n",
    "                break\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        avg_loss = total_loss / len(asr_dl)\n",
    "        print(f\"Epoch {epoch+1} - Avg Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        if num_updates >= max_updates:\n",
    "            print(f\"Reached max updates ({max_updates})\")\n",
    "            break\n",
    "    \n",
    "    return asr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64c2a7-71d8-4d31-961f-e3f06af1a05e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# asr_model = train_asr(asr_model, asr_dl, asr_optimizer, scaler, scheduler, loss_fn, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc4658-379f-447b-b658-5dbac0b05f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
