{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aba7c45-27ba-43fb-a613-e37725e92d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.requirements import *\n",
    "from src.ssl_model import *\n",
    "from src.tokenizer import *\n",
    "import csv, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8e4178-7902-470a-8d6b-9b3ceaef750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, triplets):\n",
    "        self.triplets = triplets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path_a, path_b, path_x, label = self.triplets[idx]\n",
    "        \n",
    "        wave_a = load_wave(path_a)\n",
    "        wave_b = load_wave(path_b)\n",
    "        wave_x = load_wave(path_x)\n",
    "\n",
    "        return wave_a, wave_b, wave_x, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    waves_a, waves_b, waves_x, labels = zip(*batch)\n",
    "    \n",
    "    waves_a = rnn_utils.pad_sequence(waves_a, batch_first=True)\n",
    "    waves_b = rnn_utils.pad_sequence(waves_b, batch_first=True)\n",
    "    waves_x = rnn_utils.pad_sequence(waves_x, batch_first=True)\n",
    "    \n",
    "    return waves_a.unsqueeze(1), waves_b.unsqueeze(1), waves_x.unsqueeze(1), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54cb96cc-0eb3-4967-9532-303763788e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def abx_test_batched(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_a, batch_b, batch_x, labels in loader:\n",
    "        batch_a, batch_b, batch_x = batch_a.to(device), batch_b.to(device), batch_x.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        emb_a = model.extract_features(batch_a).mean(dim=1)\n",
    "        emb_b = model.extract_features(batch_b).mean(dim=1)\n",
    "        emb_x = model.extract_features(batch_x).mean(dim=1)\n",
    "\n",
    "        sim_xa = F.cosine_similarity(emb_x, emb_a)\n",
    "        sim_xb = F.cosine_similarity(emb_x, emb_b)\n",
    "\n",
    "        # If label is 0: we want sim_xa > sim_xb\n",
    "        # If label is 1: we want sim_xb > sim_xa\n",
    "        is_match_a = (labels == 0)\n",
    "        \n",
    "        # Where label is 0, check if X is closer to A. \n",
    "        # Where label is 1, check if X is closer to B.\n",
    "        pred_correct = torch.where(is_match_a, sim_xa >= sim_xb, sim_xb >= sim_xa)\n",
    "        \n",
    "        correct += pred_correct.sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a93f7fda-f67e-48b3-9488-b9be655fd096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tsv_dataset(tsv_path):\n",
    "    dataset = []\n",
    "    with open(tsv_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        for row in reader:\n",
    "            if len(row) != 2:\n",
    "                continue\n",
    "            audio_path, text = row\n",
    "            dataset.append({\n",
    "                \"audio_path\": audio_path,\n",
    "                \"text\": text.strip()\n",
    "            })\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3b0417-0755-411a-a251-0135c620d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_chars(tokenizer, text):\n",
    "    return tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80494661-d45c-4f53-ae51-401563c14e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minimal_pairs(dataset, tokenizer, max_pairs=2000):\n",
    "    tokenized = []\n",
    "    for i, item in enumerate(dataset):\n",
    "        tokens = tokenize_chars(tokenizer, item[\"text\"])\n",
    "        tokenized.append((i, tokens))\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(len(tokenized)):\n",
    "        idx_i, tok_i = tokenized[i]\n",
    "        for j in range(i + 1, len(tokenized)):\n",
    "            idx_j, tok_j = tokenized[j]\n",
    "\n",
    "            if len(tok_i) != len(tok_j):\n",
    "                continue\n",
    "\n",
    "            diffs = [k for k in range(len(tok_i)) if tok_i[k] != tok_j[k]]\n",
    "            if len(diffs) == 1:\n",
    "                pairs.append((idx_i, idx_j, diffs[0]))\n",
    "\n",
    "            if len(pairs) >= max_pairs:\n",
    "                return pairs\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "394da53c-8d4c-4254-86a0-5d9a6d389d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wave(path, target_sr=16000):\n",
    "    waveform, sr = sf.read(path, always_2d=True)\n",
    "    waveform = torch.tensor(waveform, dtype=torch.float32)\n",
    "\n",
    "    if waveform.ndim == 2:\n",
    "        waveform = waveform.T\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    elif waveform.ndim == 1:\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "\n",
    "    wave_np = waveform.squeeze(0).numpy()\n",
    "    trimmed, _ = librosa.effects.trim(wave_np, top_db=TOP_DB)\n",
    "    waveform = torch.tensor(trimmed, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "    max_val = waveform.abs().max()\n",
    "    if max_val > 0:\n",
    "        waveform = waveform / max_val\n",
    "\n",
    "    if sr != 16_000:\n",
    "        waveform = torchaudio.functional.resample(waveform, sr, 16_000)\n",
    "\n",
    "    waveform = waveform.squeeze(0)\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc376ac9-9274-49ac-aab2-ca445a3c0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_abx_triplets(dataset, tokenizer, max_triplets=500):\n",
    "    minimal_pairs = find_minimal_pairs(dataset, tokenizer)\n",
    "    triplets = []\n",
    "\n",
    "    text_to_entries = {}\n",
    "    for d in dataset:\n",
    "        text_to_entries.setdefault(d[\"text\"], []).append(d)\n",
    "\n",
    "    for idx_A, idx_B, _ in minimal_pairs:\n",
    "        A = dataset[idx_A]\n",
    "        B = dataset[idx_B]\n",
    "\n",
    "        candidates_A = [d for d in text_to_entries[A[\"text\"]] if d[\"audio_path\"] != A[\"audio_path\"]]\n",
    "        candidates_B = [d for d in text_to_entries[B[\"text\"]] if d[\"audio_path\"] != B[\"audio_path\"]]\n",
    "\n",
    "        if candidates_A:\n",
    "            X = random.choice(candidates_A)\n",
    "            label = 0  # X matches A\n",
    "        elif candidates_B:\n",
    "            X = random.choice(candidates_B)\n",
    "            label = 1  # X matches B\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # wave_A = load_wave(A[\"audio_path\"])\n",
    "        # wave_B = load_wave(B[\"audio_path\"])\n",
    "        # wave_X = load_wave(X[\"audio_path\"])\n",
    "\n",
    "        triplets.append((A[\"audio_path\"], B[\"audio_path\"], X[\"audio_path\"], label))\n",
    "\n",
    "        # triplets.append((wave_A, wave_B, wave_X, label))\n",
    "\n",
    "        if len(triplets) >= max_triplets:\n",
    "            break\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53443238-d5c3-4082-878e-47ca52e2a43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Vocabulary Size after filtering: 494\n",
      "Blank ID: 0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer.load(os.path.join(\"data\", \"tokenizer.json\"))\n",
    "dataset = load_tsv_dataset(os.path.join(\"data\", \"metadata.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed7602e-f65d-4342-bb3a-81791b6451b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "update_ver = 9_000\n",
    "checkpoint_dict = torch.load(os.path.join('models', 'ssl_model', f'ssl_model_prototype_{update_ver}.pth'))\n",
    "ssl_state_dict = checkpoint_dict['model_state_dict']\n",
    "ssl_model = SSLModel().to(device)\n",
    "ssl_model.load_state_dict(ssl_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc54869-180e-481b-879f-f1589d681fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ABX Score: 79.60%\n"
     ]
    }
   ],
   "source": [
    "triplets = generate_abx_triplets(dataset, tokenizer, max_triplets=500)\n",
    "\n",
    "abx_triplet_ds = TripletDataset(triplets)\n",
    "abx_loader = DataLoader(abx_triplet_ds, batch_size=16, collate_fn=collate_fn)\n",
    "\n",
    "accuracy = abx_test_batched(ssl_model, abx_loader, device)\n",
    "\n",
    "print(f\"Final ABX Score: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe4a2c-af61-4b57-9b17-4ea20c83c49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
