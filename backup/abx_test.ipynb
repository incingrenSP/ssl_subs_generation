{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0108f2-96a1-459f-8103-886ee12797f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.requirements import *\n",
    "from src.ssl_model import *\n",
    "from src.tokenizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea048fe2-4a7c-4811-873c-8d076d5d7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_embedding(model, waveform):\n",
    "    features = model.extract_features(waveform)\n",
    "    embedding = features.mean(dim=1)\n",
    "\n",
    "    return embedding.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145d75e-172b-4b9a-8bab-dc02bd24eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(a, b):\n",
    "    return 1 - F.cosine_similarity(a.unsqueeze(0), b.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98806218-2a41-46c7-b5d5-b5efe167b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abx_decision(A, B, X):\n",
    "    d_xa = cosine_distance(X, A)\n",
    "    d_xb = cosine_distance(X, B)\n",
    "\n",
    "    return d_xa < d_xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13db755-1c20-493e-b9b0-a29d14aa056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abx_test(model, triplets, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for wave_A, wave_B, wave_X, label in triplets:\n",
    "        wave_A = wave_A.to(device)\n",
    "        wave_B = wave_B.to(device)\n",
    "        wave_X = wave_X.to(device)\n",
    "\n",
    "        emb_A = extract_embedding(ssl_model, wave_A)\n",
    "        emb_B = extract_embedding(ssl_model, wave_B)\n",
    "        emb_X = extract_embedding(ssl_model, wave_X)\n",
    "\n",
    "        if label == 0:\n",
    "            pred = abx_decision(emb_A, emb_B, emb_X)\n",
    "        else:\n",
    "            pred = abx_decision(emb_B, emb_A, emb_X)\n",
    "\n",
    "        correct += int(pred)\n",
    "\n",
    "    return correct / len(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625a04e-fbdc-40d9-b438-233b0b1946f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_tsv_dataset(tsv_path):\n",
    "    dataset = []\n",
    "    with open(tsv_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        for row in reader:\n",
    "            if len(row) != 2:\n",
    "                continue\n",
    "            audio_path, text = row\n",
    "            dataset.append({\n",
    "                \"audio_path\": audio_path,\n",
    "                \"text\": text.strip()\n",
    "            })\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e514f40-73b2-4f79-927c-240482e989c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_tsv_dataset(os.path.join(\"data\", \"metadata.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917a0db-d910-4469-8651-f1aaa79272cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.load(os.path.join(\"data\", \"tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bef025-f550-4a43-81ed-885fab86f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_chars(tokenizer, text):\n",
    "    return tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51371b3e-25f0-4660-a654-b7c7a7cd5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minimal_pairs(dataset, tokenizer, max_pairs=2000):\n",
    "    tokenized = []\n",
    "    for i, item in enumerate(dataset):\n",
    "        tokens = tokenize_chars(tokenizer, item[\"text\"])\n",
    "        tokenized.append((i, tokens))\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(len(tokenized)):\n",
    "        idx_i, tok_i = tokenized[i]\n",
    "        for j in range(i + 1, len(tokenized)):\n",
    "            idx_j, tok_j = tokenized[j]\n",
    "\n",
    "            if len(tok_i) != len(tok_j):\n",
    "                continue\n",
    "\n",
    "            diffs = [k for k in range(len(tok_i)) if tok_i[k] != tok_j[k]]\n",
    "            if len(diffs) == 1:\n",
    "                pairs.append((idx_i, idx_j, diffs[0]))\n",
    "\n",
    "            if len(pairs) >= max_pairs:\n",
    "                return pairs\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d240b3d6-5ef8-48bd-ad19-f8f6532b19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wave(path, target_sr=16000):\n",
    "    waveform, sr = sf.read(path, always_2d=True)\n",
    "    waveform = torch.tensor(waveform, dtype=torch.float32)\n",
    "\n",
    "    if waveform.ndim == 2:\n",
    "        waveform = waveform.T\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    elif waveform.ndim == 1:\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "\n",
    "    wave_np = waveform.squeeze(0).numpy()\n",
    "    trimmed, _ = librosa.effects.trim(wave_np, top_db=TOP_DB)\n",
    "    waveform = torch.tensor(trimmed, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "    max_val = waveform.abs().max()\n",
    "    if max_val > 0:\n",
    "        waveform = waveform / max_val\n",
    "\n",
    "    if sr != 16_000:\n",
    "        waveform = torchaudio.functional.resample(waveform, sr, 16_000)\n",
    "\n",
    "    waveform = waveform.unsqueeze(0)\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a599e-848b-4a42-ae1e-70fc472730d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_abx_triplets(dataset, tokenizer, max_triplets=500):\n",
    "    minimal_pairs = find_minimal_pairs(dataset, tokenizer)\n",
    "    triplets = []\n",
    "\n",
    "    # Index transcripts â†’ utterances\n",
    "    text_to_entries = {}\n",
    "    for d in dataset:\n",
    "        text_to_entries.setdefault(d[\"text\"], []).append(d)\n",
    "\n",
    "    for idx_A, idx_B, _ in minimal_pairs:\n",
    "        A = dataset[idx_A]\n",
    "        B = dataset[idx_B]\n",
    "\n",
    "        candidates_A = [d for d in text_to_entries[A[\"text\"]] if d[\"audio_path\"] != A[\"audio_path\"]]\n",
    "        candidates_B = [d for d in text_to_entries[B[\"text\"]] if d[\"audio_path\"] != B[\"audio_path\"]]\n",
    "\n",
    "        if candidates_A:\n",
    "            X = random.choice(candidates_A)\n",
    "            label = 0  # X matches A\n",
    "        elif candidates_B:\n",
    "            X = random.choice(candidates_B)\n",
    "            label = 1  # X matches B\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        wave_A = load_wave(A[\"audio_path\"])\n",
    "        wave_B = load_wave(B[\"audio_path\"])\n",
    "        wave_X = load_wave(X[\"audio_path\"])\n",
    "\n",
    "        triplets.append((wave_A, wave_B, wave_X, label))\n",
    "\n",
    "        if len(triplets) >= max_triplets:\n",
    "            break\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b9fefe-192f-4d68-9a0b-9d5664053b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = generate_abx_triplets(dataset, tokenizer, max_triplets=100)\n",
    "\n",
    "A, B, X, label = triplets[0]\n",
    "print(\"Triplet label:\", label)\n",
    "print(\"Wave shapes:\", A.shape, B.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb0b5f-e9bd-4528-8ccc-cdbeb98957fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_A, idx_B, _ = find_minimal_pairs(dataset, tokenizer, max_pairs=1)[0]\n",
    "print(dataset[idx_A][\"text\"], \"vs\", dataset[idx_B][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a872f5-8a00-4978-963f-bf185c5b366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "update_ver = 2_000\n",
    "checkpoint_dict = torch.load(os.path.join('models', 'ssl_model', f'ssl_model_prototype_{update_ver}.pth'))\n",
    "ssl_state_dict = checkpoint_dict['model_state_dict']\n",
    "ssl_model = SSLModel().to(device)\n",
    "ssl_model.load_state_dict(ssl_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700220dc-7675-42cd-af7d-9dbb5a10608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = abx_test(ssl_model, triplets, device)\n",
    "result * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8057c0b-c6bf-49cb-ba83-a492ba89df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABXDataset(Dataset):\n",
    "    def __init__(self, metadata_path, segment_len=32000): # e.g., 2 seconds at 16k\n",
    "        self.df = pd.read_csv(metadata_path, sep=\"\\t\")\n",
    "        self.segment_len = segment_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _get_segment(self, path):\n",
    "        waveform, _ = sf.read(path, always_2d=True)\n",
    "        waveform = torch.tensor(waveform.T, dtype=torch.float32).mean(dim=0)\n",
    "        \n",
    "        # Ensure it's long enough, else pad\n",
    "        if waveform.shape[0] < self.segment_len:\n",
    "            waveform = F.pad(waveform, (0, self.segment_len - waveform.shape[0]))\n",
    "        \n",
    "        # Random crop\n",
    "        start = torch.randint(0, waveform.shape[0] - self.segment_len + 1, (1,)).item()\n",
    "        return waveform[start : start + self.segment_len]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path_a = self.df.iloc[idx]['path']\n",
    "        \n",
    "        # A and X are two different crops/augments of the same file\n",
    "        anchor = self._get_segment(path_a)\n",
    "        positive = self._get_segment(path_a) \n",
    "        \n",
    "        # B is a random different file\n",
    "        random_idx = torch.randint(0, len(self.df), (1,)).item()\n",
    "        while random_idx == idx:\n",
    "            random_idx = torch.randint(0, len(self.df), (1,)).item()\n",
    "        \n",
    "        negative = self._get_segment(self.df.iloc[random_idx]['path'])\n",
    "        \n",
    "        return anchor, positive, negative\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_abx_val(model, abx_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for a, p, n in abx_loader:\n",
    "        # Move to device and add channel dim [B, 1, Seq]\n",
    "        a, p, n = a.to(device).unsqueeze(1), p.to(device).unsqueeze(1), n.to(device).unsqueeze(1)\n",
    "        \n",
    "        # Extract features (using the student/online encoder)\n",
    "        feat_a = model.extract_features(a).mean(dim=1) # [B, Hidden]\n",
    "        feat_p = model.extract_features(p).mean(dim=1)\n",
    "        feat_n = model.extract_features(n).mean(dim=1)\n",
    "        \n",
    "        # Compute Cosine Similarity\n",
    "        sim_pos = F.cosine_similarity(feat_a, feat_p)\n",
    "        sim_neg = F.cosine_similarity(feat_a, feat_n)\n",
    "        \n",
    "        # Successful if anchor is more similar to positive than negative\n",
    "        correct += (sim_pos > sim_neg).sum().item()\n",
    "        total += a.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"ABX Discrimination Accuracy: {accuracy:.2%}\")\n",
    "    return accuracy\n",
    "\n",
    "abx_dataset = ABXDataset(metadata_path=path, segment_len=16000 * 2)\n",
    "abx_loader = DataLoader(abx_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4014c3-f606-4e25-ba6b-028433d9aa50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
