{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3225535-3622-483f-b4f8-a830471ad1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.requirements import *\n",
    "from src.audio_handler import ASRDataset, collate_padding_asr, load_text, flatten_targets\n",
    "from src.tokenizer import Tokenizer\n",
    "from src.ssl_model import *\n",
    "from src.asr_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35509f-fb90-4f6e-81c1-11f60d1522ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = os.path.join(\"data\", \"corpus.txt\")\n",
    "if not os.path.exists(text_path):\n",
    "    path = os.path.join(\"data\", \"text\")\n",
    "    filename = \"corpus.txt\"\n",
    "    text = load_text(path)\n",
    "    with open(os.path.join(\"data\", filename), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0d67f6b-34d8-4a90-8615-700d20452169",
   "metadata": {},
   "source": [
    "df = pd.read_csv(os.path.join(\"data\", \"metadata.tsv\"), sep=\"\\t\")\n",
    "transcripts = df[\"transcript\"].tolist()\n",
    "CLEANUP_PATTERN = re.compile(r'[\\u200b-\\u200f\\u202a-\\u202e\\u2060-\\u2064\\u2066-\\u206f\\ufeff\\u00ad\\u0000-\\u001f\\x]')\n",
    "cleaned_transcripts = []\n",
    "for transcript in transcripts:\n",
    "    cleaned_text = CLEANUP_PATTERN.sub('', transcript)\n",
    "    cleaned_text = unicodedata.normalize('NFKC', cleaned_text)\n",
    "    cleaned_transcripts.append(cleaned_text)\n",
    "all_text = \"\".join(cleaned_transcripts)\n",
    "all_chars = sorted(set(\"\".join(all_text)))\n",
    "blank_token = \"<BLANK>\"\n",
    "unique_vocabs = [blank_token] + all_chars\n",
    "vocab_size = len(unique_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51874f1-f533-4d2a-885f-e921b2d76367",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"data\", \"metadata.tsv\")\n",
    "token_path = os.path.join(\"data\", \"tokenizer.json\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 16\n",
    "epochs = 999\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# refer to /models/ directory for update version\n",
    "update_ver = 160_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbac559-3126-45fb-bf40-13d721a8fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_model = SSLModel().to(device)\n",
    "ssl_model.load_state_dict(torch.load(os.path.join(\"models\", \"ssl_model\", f\"ssl_model_prototype_{update_ver}.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6096093e-4be0-4d6b-aab5-1249db98fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(token_path):\n",
    "    tokenizer = Tokenizer(text_path)\n",
    "    tokenizer.save(token_path)\n",
    "else:\n",
    "    tokenizer = Tokenizer.load(token_path)\n",
    "    \n",
    "num_classes = len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610a80b-0a7a-40ed-8008-f2eab94ef864",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_model = ASRModel(ssl_model, vocab_size=num_classes-1).to(device)\n",
    "asr_optimizer = torch.optim.Adam(asr_model.parameters(), lr=learning_rate)\n",
    "ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea0fc9-4bf7-443c-9588-2aa530d34042",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_dataset = ASRDataset(metadata_path=data_path, tokenizer=tokenizer)\n",
    "asr_dl = DataLoader(\n",
    "    dataset = asr_dataset,\n",
    "    batch_size = batch_size,\n",
    "    pin_memory = True,\n",
    "    collate_fn = collate_padding_asr,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0527f6-4398-45e3-8ccf-89572c37340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a435aa-e809-488e-8f7f-eb16bbf42df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_asr(asr_model, asr_dl, optimizer, loss_fn, epochs, device):\n",
    "    DOWNSAMPLING_FACTOR = 5 * 4 * 4 * 4\n",
    "    max_updates = 150_000\n",
    "    num_updates = 0\n",
    "    asr_model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        \n",
    "        for batch in tqdm(asr_dl):\n",
    "            waveforms, targets, input_lengths, target_lengths = batch\n",
    "            waveforms = waveforms.to(device)\n",
    "\n",
    "            targets = targets.to(device)\n",
    "            input_lengths = input_lengths // DOWNSAMPLING_FACTOR\n",
    "            input_lengths = input_lengths.to(device)\n",
    "            target_lengths = target_lengths.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            log_probs = asr_model(waveforms)\n",
    "            log_probs = log_probs.transpose(0, 1)\n",
    "\n",
    "            flat_targets = flatten_targets(targets, target_lengths).to(device)\n",
    "\n",
    "            if (flat_targets < 0).any() or (flat_targets >= log_probs.size(2)).any():\n",
    "                raise ValueError(f\"Target IDs out of range=> min={flat_targets.min()}, max={flat_targets.max()}, num_classes={log_probs.size(2)}\")\n",
    "            if (input_lengths < target_lengths).any():\n",
    "                print(\"Skipping batch: input_lengths < target_lengths\")\n",
    "                continue\n",
    "                \n",
    "            loss = loss_fn(log_probs, flat_targets, input_lengths, target_lengths)\n",
    "\n",
    "            loss.backward()\n",
    "            # gradient clipping to prevent gradient explosion (i.e. getting loss = nan)\n",
    "            torch.nn.utils.clip_grad_norm_(asr_model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "            num_updates += 1\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if num_updates % 10_000 == 0:\n",
    "                torch.save(asr_model.state_dict(), os.path.join(\"models\", \"asr_model\", f\"asr_model_prototype_{num_updates}.pth\"))\n",
    "\n",
    "            if num_updates >= max_updates:\n",
    "                break\n",
    "                \n",
    "        torch.cuda.empty_cache()\n",
    "        avg_loss = total_loss / len(asr_dl)\n",
    "        print(f\"Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if num_updates >= max_updates:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a610b-eaa1-461c-b73c-893c9f21cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_asr(asr_model, asr_dl, asr_optimizer, ctc_loss, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6696c-1199-483f-8e62-d0645aa23ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
