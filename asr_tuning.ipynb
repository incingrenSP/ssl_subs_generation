{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3225535-3622-483f-b4f8-a830471ad1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.requirements import *\n",
    "from src.audio_handler import ASRDataset, Tokenizer, collate_padding_asr, load_text\n",
    "from src.ssl_model import *\n",
    "from src.asr_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35509f-fb90-4f6e-81c1-11f60d1522ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = os.path.join(\"data\", \"corpus.txt\")\n",
    "if not os.path.exists(text_path):\n",
    "    path = os.path.join(\"data\", \"text\")\n",
    "    filename = \"corpus.txt\"\n",
    "    text = load_text(path)\n",
    "    with open(os.path.join(\"data\", filename), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e94e4b-e8c2-4e99-8832-d4e9afa930f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"data\", \"metadata.tsv\"), sep=\"\\t\")\n",
    "transcripts = df[\"transcript\"].tolist()\n",
    "all_chars = set(\"\".join(transcripts))\n",
    "unique_vocabs = list(all_chars)\n",
    "vocab_size = len(unique_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea0fc9-4bf7-443c-9588-2aa530d34042",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"data\", \"metadata.tsv\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 2\n",
    "epochs = 10\n",
    "learning_rate = 1e-4\n",
    "\n",
    "ssl_model = SSLAutoregressiveModel()\n",
    "ssl_model.to(device)\n",
    "print(\"SSl Model created\")\n",
    "ssl_model.load_state_dict(torch.load(os.path.join(\"models\", \"model_prototype_II.pth\")))\n",
    "print(\"Encoder parameters loaded\")\n",
    "\n",
    "tokenizer = Tokenizer(text_path)\n",
    "print(\"Tokenizer created\")\n",
    "asr_model = ASRModel(ssl_model, vocab_size)\n",
    "asr_model.to(device)\n",
    "print(\"ASR model created\")\n",
    "asr_optimizer = torch.optim.AdamW(asr_model.parameters(), lr=learning_rate)\n",
    "ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "\n",
    "asr_dataset = ASRDataset(metadata_path=data_path, tokenizer=tokenizer)\n",
    "print(\"ASR dataset loaded\")\n",
    "asr_dl = DataLoader(\n",
    "    dataset = asr_dataset,\n",
    "    batch_size = batch_size,\n",
    "    pin_memory = True,\n",
    "    collate_fn = collate_padding_asr,\n",
    "    shuffle=True\n",
    ")\n",
    "print(\"ASR dataloader created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbac9b2-4513-488e-b731-a333a3b734d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in asr_dl:\n",
    "    waveform, target, _, _ = batch\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd413ebd-5363-4c9d-ae6d-86037766752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_asr(asr_model, asr_dl, optimizer, loss_fn, epochs, device):\n",
    "    asr_model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "\n",
    "        for batch in tqdm(asr_dl):\n",
    "            waveforms, targets, input_lengths, target_lengths = batch\n",
    "            waveforms = waveforms.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass â†’ (B, T, vocab_size)\n",
    "            log_probs = asr_model(waveforms)\n",
    "\n",
    "            # For CTC: expected shape (T, B, C)\n",
    "            log_probs = log_probs.transpose(0, 1)\n",
    "\n",
    "            loss = loss_fn(log_probs, targets, input_lengths, target_lengths)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(asr_dl)\n",
    "        print(f\"Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a610b-eaa1-461c-b73c-893c9f21cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_asr(asr_model, asr_dl, asr_optimizer, ctc_loss, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a4df6-7f88-4999-805e-f9b3a0d92a25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
