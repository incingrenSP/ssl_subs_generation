{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3225535-3622-483f-b4f8-a830471ad1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.requirements import *\n",
    "from src.audio_handler import ASRDataset, Tokenizer, collate_padding_asr, load_text\n",
    "from src.ssl_model import *\n",
    "from src.asr_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35509f-fb90-4f6e-81c1-11f60d1522ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = os.path.join(\"data\", \"corpus.txt\")\n",
    "if not os.path.exists(text_path):\n",
    "    path = os.path.join(\"data\", \"text\")\n",
    "    filename = \"corpus.txt\"\n",
    "    text = load_text(path)\n",
    "    with open(os.path.join(\"data\", filename), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e94e4b-e8c2-4e99-8832-d4e9afa930f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"data\", \"metadata.tsv\"), sep=\"\\t\")\n",
    "transcripts = df[\"transcript\"].tolist()\n",
    "all_chars = set(\"\".join(transcripts))\n",
    "unique_vocabs = list(all_chars)\n",
    "vocab_size = len(unique_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea0fc9-4bf7-443c-9588-2aa530d34042",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"data\", \"metadata.tsv\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 2\n",
    "epochs = 10\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# select which version of ssl model to use\n",
    "# refer to /models/ directory for model names\n",
    "update_ver = 160_000\n",
    "\n",
    "ssl_model = SSLModel().to(device)\n",
    "print(\"SSl Model created\")\n",
    "ssl_model.load_state_dict(torch.load(os.path.join(\"models\", \"ssl_model\", f\"ssl_model_prototype_{update_ver}.pth\")))\n",
    "print(f\"Loaded model prototype with {update_ver} updates\")\n",
    "print(\"Encoder parameters loaded\")\n",
    "\n",
    "tokenizer = Tokenizer(text_path)\n",
    "print(\"Tokenizer created\")\n",
    "asr_model = ASRModel(ssl_model, vocab_size).to(device)\n",
    "print(\"ASR model created\")\n",
    "asr_optimizer = torch.optim.Adam(asr_model.parameters(), lr=learning_rate)\n",
    "ctc_loss = nn.CTCLoss(blank=0, reduction=\"mean\", zero_infinity=True)\n",
    "\n",
    "asr_dataset = ASRDataset(metadata_path=data_path, tokenizer=tokenizer)\n",
    "print(\"ASR dataset loaded\")\n",
    "asr_dl = DataLoader(\n",
    "    dataset = asr_dataset,\n",
    "    batch_size = batch_size,\n",
    "    pin_memory = True,\n",
    "    collate_fn = collate_padding_asr,\n",
    "    shuffle=True\n",
    ")\n",
    "print(\"ASR dataloader created\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33b7265a-6471-4a92-89f9-368ce583eecf",
   "metadata": {},
   "source": [
    "def train_asr(asr_model, asr_dl, optimizer, loss_fn, epochs, device):\n",
    "    # calculated by multiplying the stride for each conv1d in encoder\n",
    "    DOWNSAMPLING_FACTOR = 5 * 4 * 4 * 4\n",
    "    max_updates = 100\n",
    "    # max_updates = 200_000\n",
    "    num_updates = 0\n",
    "    asr_model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        \n",
    "        for batch in tqdm(asr_dl):\n",
    "            waveforms, targets, target_lengths = batch\n",
    "            waveforms = waveforms.to(device)\n",
    "            targets = targets.to(device)\n",
    "            targets[targets == -1] = 0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            log_probs = asr_model(waveforms)\n",
    "            T_out = log_probs.size(1)\n",
    "            input_lengths = torch.full(size=(waveforms.size(0),), fill_value=T_out, dtype=torch.long).to(device)\n",
    "            target_lengths = target_lengths.to(device)\n",
    "\n",
    "            log_probs = log_probs.transpose(0, 1)\n",
    "\n",
    "            loss = loss_fn(log_probs, targets, input_lengths, target_lengths)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # gradient clipping to prevent gradient explosion (i.e. getting loss = nan)\n",
    "            torch.nn.utils.clip_grad_norm_(asr_model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "            num_updates += 1\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if num_updates % 10_000 == 0:\n",
    "                torch.save(asr_model.state_dict(), os.path.join(\"models\", \"asr_model\", f\"asr_model_prototype_{num_updates}.pth\"))\n",
    "\n",
    "            if num_updates >= max_updates:\n",
    "                break\n",
    "                \n",
    "        torch.cuda.empty_cache()\n",
    "        avg_loss = total_loss / len(asr_dl)\n",
    "        print(f\"Avg Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        if num_updates >= max_updates:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a435aa-e809-488e-8f7f-eb16bbf42df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_asr(asr_model, asr_dl, optimizer, loss_fn, epochs, device):\n",
    "    DOWNSAMPLING_FACTOR = 20\n",
    "    asr_model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        \n",
    "\n",
    "        for batch in tqdm(asr_dl):\n",
    "            waveforms, targets, input_lengths, target_lengths = batch\n",
    "            waveforms = waveforms.to(device)\n",
    "            targets = targets.to(device)\n",
    "            input_lengths = input_lengths // DOWNSAMPLING_FACTOR\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            log_probs = asr_model(waveforms)\n",
    "\n",
    "            log_probs = log_probs.transpose(0, 1)\n",
    "\n",
    "            loss = loss_fn(log_probs, targets, input_lengths, target_lengths)\n",
    "\n",
    "            loss.backward()\n",
    "            # gradient clipping to prevent gradient explosion (i.e. getting loss = nan)\n",
    "            torch.nn.utils.clip_grad_norm_(asr_model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        torch.save(asr_model.state_dict(), os.path.join(\"models\", \"asr_model_prototype.pth\"))\n",
    "\n",
    "        avg_loss = total_loss / len(asr_dl)\n",
    "        print(f\"Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a610b-eaa1-461c-b73c-893c9f21cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_asr(asr_model, asr_dl, asr_optimizer, ctc_loss, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a4df6-7f88-4999-805e-f9b3a0d92a25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
